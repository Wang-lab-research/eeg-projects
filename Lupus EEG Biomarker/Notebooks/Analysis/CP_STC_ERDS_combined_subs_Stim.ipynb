{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d4092f-1ba3-49c0-a909-22a6b3039b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "from mne.stats import permutation_cluster_1samp_test as pcluster_test\n",
    "import scipy.stats as stats\n",
    "from statannotations.Annotator import Annotator\n",
    "%matplotlib inline\n",
    "# sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb8cb444-edc6-414e-b54b-b432ab964a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa3947",
   "metadata": {},
   "source": [
    "### Subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d65ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 means chronic pain, 0 means control\n",
    "sub_ids = {\n",
    "    '5186': 1,\n",
    "    '5295': 1,\n",
    "    '5648': 0,\n",
    "    '5675': 0,\n",
    "    '5873': 0,\n",
    "    '6100': 0,\n",
    "    '6106': 0,\n",
    "    '6310': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8129c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chronics: 3\n",
      "Controls: 5\n",
      "Total: 8\n"
     ]
    }
   ],
   "source": [
    "# Separate groups\n",
    "sub_ids_LP = {k:v for k,v in sub_ids.items() if v == 1}\n",
    "sub_ids_LC = {k:v for k,v in sub_ids.items() if v == 0}\n",
    "print(f\"Chronics: {len([k for k,v in sub_ids.items() if v == 1])}\")\n",
    "print(f\"Controls: {len([k for k,v in sub_ids.items() if v == 0])}\")\n",
    "print(f\"Total: {len(sub_ids)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaae428",
   "metadata": {},
   "source": [
    "### Settings for conditions/bands/methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d76539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# Include intermediate stimulus?\n",
    "include_LS = False\n",
    "\n",
    "# Data properties\n",
    "sfreq = 400  # Hz\n",
    "\n",
    "# Use canonical bands or narrower bands\n",
    "narrow_bands = True \n",
    "\n",
    "# Choose which connectivity estimates to run. \"amplitude\", \"phase\", or \"both\"\n",
    "# method_choice = \"phase\"\n",
    "method_choice = \"both\"\n",
    "\n",
    "# Load previously saved group data\n",
    "load_group_data_flag = False\n",
    "\n",
    "# Save group data?\n",
    "save_group_data_flag = True\n",
    "   \n",
    "# Evoked only or include resting too?\n",
    "# include_resting = False\n",
    "include_resting = True\n",
    "\n",
    "# Orthogonalize AEC?\n",
    "orthogonalize_AEC = True\n",
    "\n",
    "#####################################################\n",
    "# Test mode\n",
    "# plot_only_mode = True\n",
    "plot_only_mode = False\n",
    "if plot_only_mode:\n",
    "    # narrow_bands = False\n",
    "    # include_resting = False\n",
    "    load_group_data_flag = True\n",
    "    save_group_data_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab1d64c",
   "metadata": {},
   "source": [
    "### Define ROIs, frequency bands, conditions, and methods for FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4607dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# REGIONS OF INTEREST\n",
    "# Get stc only from selected labels\n",
    "# Get stc only from selected labels\n",
    "roi_names = [# Left\n",
    "             'rostralanteriorcingulate-lh', # Left Rostral ACC\n",
    "             'caudalanteriorcingulate-lh', # Left Caudal ACC\n",
    "             'postcentral-lh', # Left S1,\n",
    "             'insula-lh', 'superiorfrontal-lh', # Left Insula, Left DL-PFC,\n",
    "             'medialorbitofrontal-lh', # Left Medial-OFC\n",
    "             # CONTROLS\n",
    "             # lateral occipital\n",
    "             'lateraloccipital-lh', # Left Visual Cortex\n",
    "             'superiortemporal-lh', # Left Auditory Cortex\n",
    "             # Right\n",
    "             'rostralanteriorcingulate-rh', # Right Rostral ACC\n",
    "             'caudalanteriorcingulate-rh', # Right Caudal ACC\n",
    "             'postcentral-rh', # , Right S1\n",
    "             'insula-rh', 'superiorfrontal-rh', # Right Insula, Right DL-PFC\n",
    "             'medialorbitofrontal-rh', # Right Medial-OFC\n",
    "             # CONTROLS\n",
    "             'lateraloccipital-rh', # Right Visual Cortex\n",
    "             'superiortemporal-rh', # Right Auditory Cortex\n",
    "]\n",
    "\n",
    "# Write out ROI names as acronyms\n",
    "roi_acronyms = [\"rACC-lh\", \"dACC-lh\", \"S1-lh\", \n",
    "                \"insula-lh\", \"dlPFC-lh\", \"mOFC-lh\", \n",
    "                # CONTROLS\n",
    "                \"lOCC-lh\", \"aud-lh\",\n",
    "                \"rACC-rh\", \"dACC-rh\", \"S1-rh\", \n",
    "                \"insula-rh\", \"dlPFC-rh\", \"mOFC-rh\",\n",
    "                # CONTROLS\n",
    "                \"lOCC-rh\", \"aud-rh\", \n",
    "               ]    \n",
    "\n",
    "####################################################################\n",
    "# BANDS OF INTEREST\n",
    "if not narrow_bands:\n",
    "    Freq_Bands = {\n",
    "        # 'delta': [0, 4],\n",
    "        \"theta\": [4.0, 8.0],\n",
    "        # \"alpha\": [8.0, 13.0],\n",
    "        # \"beta\": [13.0, 30.0],\n",
    "        # \"low-gamma\": [30.0, 58.5],\n",
    "        # # \"notch\": [58.5, 61.5],\n",
    "        # \"high-gamma\": [61.5, 100.0],\n",
    "    }\n",
    "else:\n",
    "    Freq_Bands = { # Narrower bands and overlaps\n",
    "        # 'delta': [0, 4],\n",
    "        \"theta\": [4.0, 8.0],\n",
    "        \"alpha\": [8.0, 13.0],\n",
    "        \"beta\": [13.0, 30.0],\n",
    "        \"low-gamma\": [30.0, 58.5],\n",
    "        # # \"notch\": [58.5, 61.5],\n",
    "        \"high-gamma\": [61.5, 100.0],\n",
    "    }\n",
    "band_names = [band for band in Freq_Bands]\n",
    "\n",
    "####################################################################\n",
    "# CONNECTIVITY METHODS\n",
    "if method_choice == \"phase\":\n",
    "    con_methods = [\"wpli2_debiased\",\n",
    "                ]\n",
    "elif method_choice == \"amplitude\":\n",
    "    con_methods = [\n",
    "        # \"aec_pairwise\",\n",
    "        \"aec_symmetric\",\n",
    "        ]\n",
    "elif method_choice == \"both\":\n",
    "    con_methods = [\n",
    "    \"wpli2_debiased\",\n",
    "    # \"aec_pairwise\",\n",
    "    \"aec_symmetric\", # keep only symmetric for now\n",
    "    ]\n",
    "    \n",
    "####################################################################\n",
    "# CONDITIONS\n",
    "conditions = (\n",
    "    [\n",
    "        \"Hand 32 mN\",\n",
    "        \"Hand 128 mN\",\n",
    "        \"Hand 256 mN\",\n",
    "        \"Back 32 mN\",\n",
    "        \"Back 128 mN\",\n",
    "        \"Back 256 mN\",\n",
    "        \"Eyes Open\",\n",
    "        \"Eyes Closed\",\n",
    "    ]\n",
    "    if include_LS\n",
    "    else [\n",
    "        # \"Hand 32 mN\",\n",
    "        # 'Hand LS',\n",
    "        \"Hand 256 mN\",\n",
    "        # \"Back 32 mN\",\n",
    "        # 'Back LS',\n",
    "        # \"Back 256 mN\",\n",
    "        \"Eyes Open\",\n",
    "        # \"Eyes Closed\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Choose to exclude resting state data\n",
    "conditions = conditions if include_resting else [\n",
    "    c for c in conditions if \"Eyes\" not in c\n",
    "]\n",
    "\n",
    "####################################################################\n",
    "# CONDITION DICTIONARY\n",
    "condition_dict = {\n",
    "        \"Hand 32 mN\": 0,\n",
    "        'Hand LS': 1,\n",
    "        \"Hand 256 mN\": 2,\n",
    "        \"Back 32 mN\": 3,\n",
    "        'Back LS': 4,\n",
    "        \"Back 256 mN\": 5,\n",
    "        \"Eyes Open\": 6,\n",
    "        \"Eyes Closed\": 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eec3b9c-81db-4154-8fed-315728970cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_multiple_elements(list_object, indices):\n",
    "    indices = sorted(indices, reverse=True)\n",
    "    for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)## define functions for extracting relevant epochs\n",
    "            \n",
    "def stats_plot(df, save_path, site, feature):\n",
    "    '''\n",
    "    df = dataframe (mean, peak, auc)\n",
    "    save_path = directory to save stats PNG and TXT files\n",
    "    site = 'hand' or 'back'\n",
    "    feature = 'mean','peak','auc'    \n",
    "    '''    \n",
    "\n",
    "    pairs=[((f,conditions[0]),(f,conditions[1])) for f in freq_bands_of_interest]\n",
    "    \n",
    "    for roi_idx, roi in enumerate(roi_names):        \n",
    "        df_ch_tmp=df.query(f\"channel=='{roi}'\")\n",
    "       \n",
    "\n",
    "        #stats plot\n",
    "        scale=2\n",
    "        plt.figure(figsize=(19.2*scale,10.8*scale));\n",
    "        sns.set_style('white')\n",
    "        sns.set_context('paper', font_scale=6)\n",
    "        ax_tmp = sns.boxplot(data=df_ch_tmp,x='band', y='value', hue='condition',\n",
    "                palette='pastel', order=freq_bands_of_interest,\n",
    "                hue_order=conditions, showfliers=False,\n",
    "                linewidth=0.5)\n",
    "\n",
    "        ax_tmp.set_title(f\"{roi_names[roi_idx]}\",pad=130)\n",
    "\n",
    "        #stats output\n",
    "        x='band'\n",
    "        y='value'\n",
    "        hue='condition'\n",
    "        order=freq_bands_of_interest\n",
    "        hue_order = conditions\n",
    "\n",
    "        test = 'Mann-Whitney'\n",
    "        print(f\"******************************************************{roi} {test}******************************************************\")\n",
    "        annot = Annotator(ax_tmp, pairs, data=df_ch_tmp, x=x, y=y, hue=hue, order=order,hue_order=hue_order)\n",
    "        annot.configure(test=test, text_format='star', loc='outside',comparisons_correction=None)\n",
    "        annot.apply_test()\n",
    "        annot.annotate()\n",
    "\n",
    "        # save plot and tfr data\n",
    "        save_fname = f\"{roi}_{feature}_stim-based_{site}_set_{subject_set}\"\n",
    "        # print(df)\n",
    "\n",
    "        plt.xlabel(\"Frequency Band\")\n",
    "        plt.ylabel(\"Scaled Power (x100)\")\n",
    "        plt.gca().legend().set_title('')\n",
    "\n",
    "        # if site=='hand': \n",
    "        #     conditions=['Chronic Pain Hand 256 mN','Healthy Control Hand 256 mN']\n",
    "        # elif site=='back': \n",
    "        #     conditions=['Chronic Pain Back 256 mN','Healthy Control Back 256 mN']\n",
    "\n",
    "        handles,_ = ax_tmp.get_legend_handles_labels()\n",
    "        ax_tmp.legend(handles, conditions, loc=\"best\")\n",
    "        plt.savefig(os.path.join(save_path,save_fname+\".jpg\"))\n",
    "        plt.figure()\n",
    "\n",
    "        # tfr data as csv\n",
    "        df_ch_tmp.to_csv(os.path.join(save_path,save_fname+\".csv\"))\n",
    "        display.clear_output(wait=True)  \n",
    "     \n",
    "       #save number of trials in df  \n",
    "        total_epochs=df_ch_tmp['epoch'].count()\n",
    "        total_trials=int(total_epochs/(len(freq_bands_of_interest)))\n",
    "        with open(save_path+ f\"Total Number of Trials set {subject_set}.txt\", \"w\") as txt_file:\n",
    "            txt_file.write(f\"{total_trials}\")\n",
    "        display.clear_output(wait=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0cec54-6fb3-4974-bc76-e8e4754d3a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SETTINGS:\n",
    "\n",
    "# 1. Choose all subjects, only CP, or only HC\n",
    "group = \"Chronic Pain\"\n",
    "# group = \"Healthy Controls\"\n",
    "if group == \"Chronic Pain\":\n",
    "    chosen_list = [el for el in sub_ids if el.startswith('0')]\n",
    "else:\n",
    "    chosen_list = [el for el in sub_ids if el.startswith('C')]\n",
    "\n",
    "# 3. Set directory length requirement for starting analysis\n",
    "min_path_len = 0\n",
    "\n",
    "#4. Manually name the set of subjects being used \n",
    "subject_set= '1'\n",
    "\n",
    "# Paths\n",
    "processed_info_path = \"../../../../George Kenefati/EEG/Data/Processed Data\"\n",
    "parent_data_path = \"../../../../George Kenefati/EEG/Data/Source Time Courses/\"\n",
    "    \n",
    "# Globals\n",
    "Fs = 250 # Hz\n",
    "\n",
    "tmin,tmax=-0.2,0.8\n",
    "bmax=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a41a7a4-2655-417b-b81a-7101e5f6e9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../George Kenefati/EEG/Data/Source Time Courses/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df_peak_all_back\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#loop through to analyze each subject \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_data_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      8\u001b[0m     sub_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# reset\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# ignores hidden files\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../George Kenefati/EEG/Data/Source Time Courses/'"
     ]
    }
   ],
   "source": [
    "df_mean_all_hand=[]\n",
    "df_peak_all_hand=[]\n",
    "df_mean_all_back=[]\n",
    "df_peak_all_back=[]\n",
    "\n",
    "#loop through to analyze each subject \n",
    "for sub_folder in os.listdir(parent_data_path):\n",
    "    sub_num=' ' # reset\n",
    "    # ignores hidden files\n",
    "    if sub_folder.startswith('.') or sub_folder not in chosen_list:\n",
    "        continue\n",
    "    else:\n",
    "        sub_num=sub_folder\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ LOAD SUBJECT DATA @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "    data_path = os.path.join(parent_data_path,sub_num)\n",
    "\n",
    "    #go through all the below code and then go to next subject  \n",
    "    exam_hand_flag='lh' # right-handed exam for most subjects\n",
    "    if sub_num==\"055\": # the only left-sided subject. regions must be contralateral.\n",
    "        roi_names = [# Right\n",
    "        'rostralanteriorcingulate-rh', # Right Rostral ACC\n",
    "        'caudalanteriorcingulate-rh', # Right Caudal ACC\n",
    "        'postcentral-rh', # , Right S1\n",
    "        'insula-rh', 'superiorfrontal-rh', # Right Insula, Right DL-PFC\n",
    "        'medialorbitofrontal-rh'] # Right Medial-PFC\n",
    "        exam_hand_flag='rh' # 055 is the only left-sided exam\n",
    "    else:\n",
    "        roi_names = [# Left\n",
    "         'rostralanteriorcingulate-lh', # Left Rostral ACC\n",
    "         'caudalanteriorcingulate-lh', # Left Caudal ACC\n",
    "         'postcentral-lh', # Left S1,\n",
    "         'insula-lh', 'superiorfrontal-lh', # Left Insula, Left DL-PFC,\n",
    "         'medialorbitofrontal-lh'] # Left Medial-PFC\n",
    "\n",
    "    n_channels = len(roi_names)\n",
    "\n",
    "    print(f\"{sub_num}\\nReading Source Space data...\\n\")\n",
    "\n",
    "    stc_names_lst=[]\n",
    "    stc_objects_lst=[]\n",
    "    for stc_file in os.listdir(data_path): #loop should look for file in subject folder \n",
    "        if stc_file.endswith('.stc') and exam_hand_flag in stc_file: \n",
    "            print(stc_file)\n",
    "            stc_tmp=mne.read_source_estimate(os.path.join(data_path,stc_file))\n",
    "            stc_names_lst.append(os.path.join(data_path,stc_file))\n",
    "            stc_objects_lst.append(stc_tmp)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Import processed info @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "    # Process only subjects with 64 channel data, for homogeneity\n",
    "    print(f\"Reading stim_labels, epo_times, pain_ratings, drop_log for Subject {sub_num}...\")\n",
    "\n",
    "    stim_labels = scio.loadmat(os.path.join(processed_info_path,sub_num+'_stim_labels.mat'))\n",
    "    stim_labels = stim_labels['stim_labels'].tolist()[0]\n",
    "\n",
    "    print(f\"\\n*len(stim_labels) = {len(stim_labels)}*\")\n",
    "\n",
    "    # Load in sample times for stimuli\n",
    "    epo_times = scio.loadmat(os.path.join(processed_info_path,sub_num+'_epo_times.mat'))\n",
    "    epo_times_raw = epo_times['epo_times'] # leave as array\n",
    "    epo_times = [el[0] for el in epo_times_raw]\n",
    "\n",
    "    print(f\"*len(epo_times) = {len(epo_times)}*\\n\")\n",
    "\n",
    "    # Load in pain rating for each stimuli\n",
    "    pain_ratings = scio.loadmat(os.path.join(processed_info_path,sub_num+'_pain_ratings.mat'))\n",
    "    pain_ratings = pain_ratings['pain_ratings'].tolist()[0]\n",
    "\n",
    "    print(f\"*len(pain_ratings) = {len(pain_ratings)}*\\n\")\n",
    "\n",
    "    # Load in drop log for bad trials\n",
    "    drop_log = scio.loadmat(os.path.join(processed_info_path,sub_num+'_drop_log.mat'))\n",
    "    drop_log = drop_log['drop_log'] # leave as array\n",
    "\n",
    "    print(f\"*len(drop_log) = {drop_log.shape[0]}*\\n\")\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "#     # Dict mapping key press labels to conditions\n",
    "#     if 4 not in stim_labels or 7 not in stim_labels: \n",
    "#          event_ids_dict = {\n",
    "#                   'Hand HS': 3, # hand YES pain\n",
    "#                   'Hand LS': 5, # hand NO pain\n",
    "#                   'Back HS': 6, # hand YES pain\n",
    "#                   'Back LS': 8, # hand NO pain\n",
    "#                 }\n",
    "#     else: \n",
    "#         event_ids_dict = {\n",
    "#                   'Hand HS': 3, # hand YES pain\n",
    "#                   'Hand 0S': 4, # hand MED pain\n",
    "#                   'Hand LS': 5, # hand NO pain\n",
    "#                   'Back HS': 6, # back YES pain\n",
    "#                   'Back 0S': 7, # back MED pain\n",
    "#                   'Back LS': 8, # back NO pain\n",
    "#                 }\n",
    "    \n",
    "    site='hand'\n",
    "    # Limit events to selection\n",
    "    event_ids_dict = {\n",
    "              'Hand HS': 3, # hand YES pain\n",
    "              # 'Hand 0S': 4, # hand MED pain\n",
    "              'Hand LS': 5,} # hand NO pain\n",
    "    conditions=['Hand HS','Hand LS']\n",
    "     # select all back trials for deletion\n",
    "    undesired_trial_ids = [4,6,7,8] # Hand LS + All back\n",
    "    other_trials = [i for i,el in enumerate(stim_labels) if el in undesired_trial_ids]\n",
    "\n",
    "    delete_multiple_elements(pain_ratings, other_trials)\n",
    "    delete_multiple_elements(stim_labels, other_trials)\n",
    "    delete_multiple_elements(epo_times, other_trials)        \n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ EXTRACT DATA FROM STC FOR EPO @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Extract data from STC\n",
    "    stc_data_chs_array = np.zeros((len(roi_names),len(epo_times),Fs))\n",
    "    stc_data_trials_tmp=np.zeros((len(epo_times),Fs))\n",
    "    for j,stc in enumerate(stc_objects_lst): # for each roi\n",
    "        extracted_data_tmp=stc.data\n",
    "        for i in range(len(epo_times)): # for each trial\n",
    "            #all vertices\n",
    "            all_vertices_tmp=extracted_data_tmp[:,int(epo_times[i]+tmin*Fs):int(epo_times[i]+tmax*Fs)]\n",
    "            #averaged vertices\n",
    "            vertices_averaged_tmp=np.mean(all_vertices_tmp,axis=0)\n",
    "            #store trials x time data in numpy array\n",
    "            stc_data_trials_tmp[i,:] = vertices_averaged_tmp\n",
    "        stc_data_chs_array[j,...] = stc_data_trials_tmp\n",
    "    #data in Array format \n",
    "    stc_data_chs_corrected_array=np.transpose(stc_data_chs_array,(1,0,2))\n",
    "\n",
    "#     # determine which indices are baseline vs stimulus\n",
    "#     # baseline\n",
    "#     len_baseline_samples = int((bmax-tmin)*Fs)\n",
    "#     print(len_baseline_samples)\n",
    "#     # stimulus\n",
    "#     len_stimulus_samples = int((tmax-bmax)*Fs)\n",
    "#     print(len_stimulus_samples)\n",
    "\n",
    "#     # z-score data by for loop\n",
    "#     data_epo=combined_stc_data_trials\n",
    "#     print(data_epo.shape)\n",
    "#     data_epo_zcore=np.copy(data_epo)\n",
    "#     for i in range(data_epo.shape[0]): # for each epoch\n",
    "#         for j in range(data_epo.shape[1]): # for each channel\n",
    "#             # compute mean and std of baseline\n",
    "#             base_mean = np.mean(data_epo[i,j,:len_baseline_samples])\n",
    "#             base_std = np.std(data_epo[i,j,:len_baseline_samples])\n",
    "\n",
    "#             # compute z-scored data from baseline stats\n",
    "#             data_epo_zcore[i,j,:] = (data_epo[i,j,:]-base_mean)/base_std\n",
    "\n",
    "#     # compare data before and after z-score\n",
    "#     print(data_epo[0,0,len_baseline_samples:len_baseline_samples+10],'\\n')\n",
    "#     print(data_epo_zcore[0,0,len_baseline_samples:len_baseline_samples+10])\n",
    "\n",
    "#     zepochs = mne.EpochsArray(data=data_epo_zcore,\n",
    "#                               info=info,\n",
    "#                               tmin=tmin,\n",
    "#                               events=events,\n",
    "#                               event_id=event_ids_dict,\n",
    "#                               baseline=(None,bmax),\n",
    "#                               )\n",
    "#     print(zepochs)\n",
    "#     epochs=zepochs \n",
    "#     del zepochs\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ CREATE EPOCHS OBJECT @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Replace Epochs object with Z-scored data\n",
    "    info = mne.create_info(roi_names, sfreq=Fs,ch_types='eeg')\n",
    "    # create events array for Epochs object\n",
    "    events=np.array([[epo_times[i],0,stim_labels[i]] for i in range(len(epo_times))])\n",
    "\n",
    "    data_epo=stc_data_chs_corrected_array\n",
    "    epochs = mne.EpochsArray(data=data_epo,\n",
    "                              info=info,\n",
    "                              tmin=tmin,\n",
    "                              events=events,\n",
    "                              event_id=event_ids_dict,\n",
    "                              baseline=(None,bmax),\n",
    "                              )\n",
    "    print(epochs)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ SET UP ERDS @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    freqs = np.arange(1, 100)  # frequencies from 2-35Hz\n",
    "    # vmin, vmax = -1, 1.5  # set min and max ERDS values in plot\n",
    "\n",
    "    baseline = (tmin, bmax)  # baseline interval (in s)\n",
    "    # cnorm = TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)  # min, center & max ERDS\n",
    "\n",
    "    # kwargs = dict(n_permutations=100, step_down_p=0.05, seed=1,\n",
    "                  # buffer_size=None, out_type='mask')  # for cluster test\n",
    "\n",
    "    #Perform time-frequency decomposition over all epochs\n",
    "    tfr = tfr_multitaper(epochs, freqs=freqs, n_cycles=freqs, use_fft=True,\n",
    "                         return_itc=False, average=False, decim=2)\n",
    "    tfr.crop(tmin, tmax).apply_baseline(baseline, mode=\"percent\")\n",
    "\n",
    "#     for event in event_ids_dict:\n",
    "#         # select desired epochs for visualization\n",
    "#         tfr_ev = tfr[event]\n",
    "\n",
    "#         widths_lst = [10]*n_channels\n",
    "#         widths_lst.append(1)\n",
    "#         fig, axes = plt.subplots(1, n_channels+1, figsize=(12, 4),\n",
    "#                                  gridspec_kw={\"width_ratios\": widths_lst})\n",
    "#         for ch, ax in enumerate(axes[:-1]):  # for each channel\n",
    "#             # positive clusters\n",
    "#             _, c1, p1, _ = pcluster_test(tfr_ev.data[:, ch], tail=1, **kwargs)\n",
    "#             # negative clusters\n",
    "#             _, c2, p2, _ = pcluster_test(tfr_ev.data[:, ch], tail=-1, **kwargs)\n",
    "\n",
    "#             # note that we keep clusters with p <= 0.05 from the combined clusters\n",
    "#             # of two independent tests; in this example, we do not correct for\n",
    "#             # these two comparisons\n",
    "#             c = np.stack(c1 + c2, axis=2)  # combined clusters\n",
    "#             p = np.concatenate((p1, p2))  # combined p-values\n",
    "#             mask = c[..., p <= 0.05].any(axis=-1)\n",
    "\n",
    "#             # plot TFR (ERDS map with masking)\n",
    "#             tfr_ev.average().plot([ch], cmap=\"RdBu\", cnorm=cnorm, axes=ax,\n",
    "#                                   colorbar=False, show=False, mask=mask,\n",
    "#                                   mask_style=\"mask\")\n",
    "\n",
    "        #     ax.set_title(epochs.ch_names[ch], fontsize=10)\n",
    "        #     ax.axvline(0, linewidth=1, color=\"black\", linestyle=\":\")  # event\n",
    "        #     if ch != 0:\n",
    "        #         ax.set_ylabel(\"\")\n",
    "        #         ax.set_yticklabels(\"\")\n",
    "        # fig.colorbar(axes[0].images[-1], cax=axes[-1]).ax.set_yscale(\"linear\")\n",
    "        # fig.suptitle(f\"ERDS ({event})\")\n",
    "        # plt.show()\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ SET UP PANDAS DATAFRAMES @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Export tfr to pandas df in seconds\n",
    "    # df = tfr.to_data_frame(time_format=None, long_format=False)\n",
    "    # df.head()\n",
    "\n",
    "    #Plot with confidence bands \n",
    "    df = tfr.to_data_frame(time_format=None, long_format=True)\n",
    "\n",
    "    # Map to frequency bands:\n",
    "    freq_bounds = {'_': 0,\n",
    "                   'delta': 4,\n",
    "                   'theta': 8,\n",
    "                   'alpha': 13,\n",
    "                   'beta': 35,\n",
    "                   'low-gamma': 55,\n",
    "                   'notch': 65,\n",
    "                   'high-gamma': 100}\n",
    "    df['band'] = pd.cut(df['freq'], list(freq_bounds.values()),\n",
    "                        labels=list(freq_bounds)[1:])\n",
    "\n",
    "    # Filter to retain only relevant frequency bands:\n",
    "    freq_bands_of_interest = [\n",
    "                              # 'delta', \n",
    "                              'theta', \n",
    "                              'alpha', \n",
    "                              'beta', \n",
    "                              'low-gamma', \n",
    "                              'high-gamma']\n",
    "    df = df[df.band.isin(freq_bands_of_interest)]\n",
    "    df['band'] = df['band'].cat.remove_unused_categories()\n",
    "\n",
    "    # Order channels for plotting:\n",
    "    df['channel'] = df['channel'].cat.reorder_categories(tuple(roi_names),\n",
    "                                                         ordered=True)\n",
    "\n",
    "    # g = sns.FacetGrid(df, row='band', col='channel', margin_titles=True)\n",
    "    # g.map(sns.lineplot, 'time', 'value', 'condition', n_boot=10)\n",
    "    # axline_kw = dict(color='black', linestyle='dashed', linewidth=0.5, alpha=0.5)\n",
    "    # g.map(plt.axhline, y=0, **axline_kw)\n",
    "    # g.map(plt.axvline, x=0, **axline_kw)\n",
    "    # g.set(xlim=(tmin+0.5,tmax-0.5))\n",
    "    # # g.set(ylim=(None, 3))\n",
    "    # g.set_axis_labels(\"Time (s)\", \"ERDS (%)\")\n",
    "    # g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    # g.add_legend(ncol=2, loc='lower center')\n",
    "    # g.fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.08)\n",
    "    # plt.show();\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    # Plot the ERDS based on average, peak amplitude, and area-under-the-curve (AUC), one by one.\n",
    "    df_mean = (df.query(f\"time > {bmax} & time < {tmax}\")\n",
    "                 .groupby(['condition', 'epoch','band', 'channel'])[['value']]\n",
    "                 .mean()\n",
    "                 .dropna(subset=['value']) # needed to remove taking average over non-numeric values\n",
    "                 .reset_index())\n",
    "\n",
    "    df_mean_all_hand.append(df_mean) #when it loops through each subject, will save the mean in the array\n",
    "\n",
    "    df_peak = (df.query(f\"time > {bmax} & time < {tmax}\")\n",
    "                 .groupby(['condition', 'epoch','band', 'channel'])[['value']]\n",
    "                 .max() # peak amplitude\n",
    "                 .dropna(subset=['value']) # needed to remove taking average over non-numeric values\n",
    "                 .reset_index())\n",
    "    df_peak_all_hand.append(df_peak) #when it loops through each subject, will save the peak\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Repeat for back @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "    \n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Re-import processed info @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "    # Process only subjects with 64 channel data, for homogeneity\n",
    "    print(f\"Reading stim_labels, epo_times, pain_ratings, drop_log for Subject {sub_num}...\")\n",
    "\n",
    "    stim_labels = scio.loadmat(os.path.join(processed_info_path,sub_num+'_stim_labels.mat'))\n",
    "    stim_labels = stim_labels['stim_labels'].tolist()[0]\n",
    "\n",
    "    print(f\"\\n*len(stim_labels) = {len(stim_labels)}*\")\n",
    "\n",
    "    # Load in sample times for stimuli\n",
    "    epo_times = scio.loadmat(os.path.join(processed_info_path,sub_num+'_epo_times.mat'))\n",
    "    epo_times_raw = epo_times['epo_times'] # leave as array\n",
    "    epo_times = [el[0] for el in epo_times_raw]\n",
    "\n",
    "    print(f\"*len(epo_times) = {len(epo_times)}*\\n\")\n",
    "\n",
    "    # Load in pain rating for each stimuli\n",
    "    pain_ratings = scio.loadmat(os.path.join(processed_info_path,sub_num+'_pain_ratings.mat'))\n",
    "    pain_ratings = pain_ratings['pain_ratings'].tolist()[0]\n",
    "\n",
    "    print(f\"*len(pain_ratings) = {len(pain_ratings)}*\\n\")\n",
    "\n",
    "    # Load in drop log for bad trials\n",
    "    drop_log = scio.loadmat(os.path.join(processed_info_path,sub_num+'_drop_log.mat'))\n",
    "    drop_log = drop_log['drop_log'] # leave as array\n",
    "\n",
    "    print(f\"*len(drop_log) = {drop_log.shape[0]}*\\n\")\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    site='back'\n",
    "    # Limit events to selection\n",
    "    event_ids_dict = {\n",
    "              'Back HS': 6, # back YES pain\n",
    "              # 'Back 0S': 7, # back MED pain\n",
    "              'Back LS': 8,} # back NO pain \n",
    "    conditions=['Back HS','Back LS']\n",
    "    # select all hand trials for deletion\n",
    "    undesired_trial_ids = [3,4,5,7] # Hand LS + All back\n",
    "    other_trials = [i for i,el in enumerate(stim_labels) if el in undesired_trial_ids]\n",
    "\n",
    "    delete_multiple_elements(pain_ratings, other_trials)\n",
    "    delete_multiple_elements(stim_labels, other_trials)\n",
    "    delete_multiple_elements(epo_times, other_trials)        \n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ EXTRACT DATA FROM STC FOR EPO @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Extract data from STC\n",
    "    stc_data_chs_array = np.zeros((len(roi_names),len(epo_times),Fs))\n",
    "    stc_data_trials_tmp=np.zeros((len(epo_times),Fs))\n",
    "    for j,stc in enumerate(stc_objects_lst): # for each roi\n",
    "        extracted_data_tmp=stc.data\n",
    "        for i in range(len(epo_times)): # for each trial\n",
    "            #all vertices\n",
    "            all_vertices_tmp=extracted_data_tmp[:,int(epo_times[i]+tmin*Fs):int(epo_times[i]+tmax*Fs)]\n",
    "            #averaged vertices\n",
    "            vertices_averaged_tmp=np.mean(all_vertices_tmp,axis=0)\n",
    "            #store trials x time data in numpy array\n",
    "            stc_data_trials_tmp[i,:] = vertices_averaged_tmp\n",
    "        stc_data_chs_array[j,...] = stc_data_trials_tmp\n",
    "    #data in Array format \n",
    "    stc_data_chs_corrected_array=np.transpose(stc_data_chs_array,(1,0,2))\n",
    "\n",
    "#     # determine which indices are baseline vs stimulus\n",
    "#     # baseline\n",
    "#     len_baseline_samples = int((bmax-tmin)*Fs)\n",
    "#     print(len_baseline_samples)\n",
    "#     # stimulus\n",
    "#     len_stimulus_samples = int((tmax-bmax)*Fs)\n",
    "#     print(len_stimulus_samples)\n",
    "\n",
    "#     # z-score data by for loop\n",
    "#     data_epo=combined_stc_data_trials\n",
    "#     print(data_epo.shape)\n",
    "#     data_epo_zcore=np.copy(data_epo)\n",
    "#     for i in range(data_epo.shape[0]): # for each epoch\n",
    "#         for j in range(data_epo.shape[1]): # for each channel\n",
    "#             # compute mean and std of baseline\n",
    "#             base_mean = np.mean(data_epo[i,j,:len_baseline_samples])\n",
    "#             base_std = np.std(data_epo[i,j,:len_baseline_samples])\n",
    "\n",
    "#             # compute z-scored data from baseline stats\n",
    "#             data_epo_zcore[i,j,:] = (data_epo[i,j,:]-base_mean)/base_std\n",
    "\n",
    "#     # compare data before and after z-score\n",
    "#     print(data_epo[0,0,len_baseline_samples:len_baseline_samples+10],'\\n')\n",
    "#     print(data_epo_zcore[0,0,len_baseline_samples:len_baseline_samples+10])\n",
    "\n",
    "#     zepochs = mne.EpochsArray(data=data_epo_zcore,\n",
    "#                               info=info,\n",
    "#                               tmin=tmin,\n",
    "#                               events=events,\n",
    "#                               event_id=event_ids_dict,\n",
    "#                               baseline=(None,bmax),\n",
    "#                               )\n",
    "#     print(zepochs)\n",
    "#     epochs=zepochs \n",
    "#     del zepochs\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ CREATE EPOCHS OBJECT @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Replace Epochs object with Z-scored data\n",
    "    info = mne.create_info(roi_names, sfreq=Fs,ch_types='eeg')\n",
    "    # create events array for Epochs object\n",
    "    events=np.array([[epo_times[i],0,stim_labels[i]] for i in range(len(epo_times))])\n",
    "\n",
    "    data_epo=stc_data_chs_corrected_array\n",
    "    epochs = mne.EpochsArray(data=data_epo,\n",
    "                              info=info,\n",
    "                              tmin=tmin,\n",
    "                              events=events,\n",
    "                              event_id=event_ids_dict,\n",
    "                              baseline=(None,bmax),\n",
    "                              )\n",
    "    print(epochs)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ SET UP ERDS @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    freqs = np.arange(1, 100)  # frequencies from 2-35Hz\n",
    "    # vmin, vmax = -1, 1.5  # set min and max ERDS values in plot\n",
    "\n",
    "    baseline = (tmin, bmax)  # baseline interval (in s)\n",
    "    # cnorm = TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax)  # min, center & max ERDS\n",
    "\n",
    "    # kwargs = dict(n_permutations=100, step_down_p=0.05, seed=1,\n",
    "                  # buffer_size=None, out_type='mask')  # for cluster test\n",
    "\n",
    "    #Perform time-frequency decomposition over all epochs\n",
    "    tfr = tfr_multitaper(epochs, freqs=freqs, n_cycles=freqs, use_fft=True,\n",
    "                         return_itc=False, average=False, decim=2)\n",
    "    tfr.crop(tmin, tmax).apply_baseline(baseline, mode=\"percent\")\n",
    "\n",
    "#     for event in event_ids_dict:\n",
    "#         # select desired epochs for visualization\n",
    "#         tfr_ev = tfr[event]\n",
    "\n",
    "#         widths_lst = [10]*n_channels\n",
    "#         widths_lst.append(1)\n",
    "#         fig, axes = plt.subplots(1, n_channels+1, figsize=(12, 4),\n",
    "#                                  gridspec_kw={\"width_ratios\": widths_lst})\n",
    "#         for ch, ax in enumerate(axes[:-1]):  # for each channel\n",
    "#             # positive clusters\n",
    "#             _, c1, p1, _ = pcluster_test(tfr_ev.data[:, ch], tail=1, **kwargs)\n",
    "#             # negative clusters\n",
    "#             _, c2, p2, _ = pcluster_test(tfr_ev.data[:, ch], tail=-1, **kwargs)\n",
    "\n",
    "#             # note that we keep clusters with p <= 0.05 from the combined clusters\n",
    "#             # of two independent tests; in this example, we do not correct for\n",
    "#             # these two comparisons\n",
    "#             c = np.stack(c1 + c2, axis=2)  # combined clusters\n",
    "#             p = np.concatenate((p1, p2))  # combined p-values\n",
    "#             mask = c[..., p <= 0.05].any(axis=-1)\n",
    "\n",
    "#             # plot TFR (ERDS map with masking)\n",
    "#             tfr_ev.average().plot([ch], cmap=\"RdBu\", cnorm=cnorm, axes=ax,\n",
    "#                                   colorbar=False, show=False, mask=mask,\n",
    "#                                   mask_style=\"mask\")\n",
    "\n",
    "        #     ax.set_title(epochs.ch_names[ch], fontsize=10)\n",
    "        #     ax.axvline(0, linewidth=1, color=\"black\", linestyle=\":\")  # event\n",
    "        #     if ch != 0:\n",
    "        #         ax.set_ylabel(\"\")\n",
    "        #         ax.set_yticklabels(\"\")\n",
    "        # fig.colorbar(axes[0].images[-1], cax=axes[-1]).ax.set_yscale(\"linear\")\n",
    "        # fig.suptitle(f\"ERDS ({event})\")\n",
    "        # plt.show()\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    # @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ SET UP PANDAS DATAFRAMES @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "\n",
    "    #Export tfr to pandas df in seconds\n",
    "    # df = tfr.to_data_frame(time_format=None, long_format=False)\n",
    "    # df.head()\n",
    "\n",
    "    #Plot with confidence bands \n",
    "    df = tfr.to_data_frame(time_format=None, long_format=True)\n",
    "\n",
    "    # Map to frequency bands:\n",
    "    freq_bounds = {'_': 0,\n",
    "                   'delta': 4,\n",
    "                   'theta': 8,\n",
    "                   'alpha': 13,\n",
    "                   'beta': 35,\n",
    "                   'low-gamma': 55,\n",
    "                   'notch': 65,\n",
    "                   'high-gamma': 100}\n",
    "    df['band'] = pd.cut(df['freq'], list(freq_bounds.values()),\n",
    "                        labels=list(freq_bounds)[1:])\n",
    "\n",
    "    # Filter to retain only relevant frequency bands:\n",
    "    freq_bands_of_interest = [\n",
    "                              # 'delta', \n",
    "                              'theta', \n",
    "                              'alpha', \n",
    "                              'beta', \n",
    "                              'low-gamma', \n",
    "                              'high-gamma']\n",
    "    df = df[df.band.isin(freq_bands_of_interest)]\n",
    "    df['band'] = df['band'].cat.remove_unused_categories()\n",
    "\n",
    "    # Order channels for plotting:\n",
    "    df['channel'] = df['channel'].cat.reorder_categories(tuple(roi_names),\n",
    "                                                         ordered=True)\n",
    "\n",
    "    # g = sns.FacetGrid(df, row='band', col='channel', margin_titles=True)\n",
    "    # g.map(sns.lineplot, 'time', 'value', 'condition', n_boot=10)\n",
    "    # axline_kw = dict(color='black', linestyle='dashed', linewidth=0.5, alpha=0.5)\n",
    "    # g.map(plt.axhline, y=0, **axline_kw)\n",
    "    # g.map(plt.axvline, x=0, **axline_kw)\n",
    "    # g.set(xlim=(tmin+0.5,tmax-0.5))\n",
    "    # # g.set(ylim=(None, 3))\n",
    "    # g.set_axis_labels(\"Time (s)\", \"ERDS (%)\")\n",
    "    # g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "    # g.add_legend(ncol=2, loc='lower center')\n",
    "    # g.fig.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.08)\n",
    "    # plt.show();\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    # Plot the ERDS based on average, peak amplitude, and area-under-the-curve (AUC), one by one.\n",
    "    df_mean = (df.query(f\"time > {bmax} & time < {tmax}\")\n",
    "                 .groupby(['condition', 'epoch','band', 'channel'])[['value']]\n",
    "                 .mean()\n",
    "                 .dropna(subset=['value']) # needed to remove taking average over non-numeric values\n",
    "                 .reset_index())\n",
    "\n",
    "    df_mean_all_back.append(df_mean) #when it loops through each subject, will save the mean in the array\n",
    "\n",
    "    df_peak = (df.query(f\"time > {bmax} & time < {tmax}\")\n",
    "                 .groupby(['condition', 'epoch','band', 'channel'])[['value']]\n",
    "                 .max() # peak amplitude\n",
    "                 .dropna(subset=['value']) # needed to remove taking average over non-numeric values\n",
    "                 .reset_index())\n",
    "    df_peak_all_back.append(df_peak) #when it loops through each subject, will save the peak\n",
    "\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e1109-a2ef-48e5-8c4e-b542e934cede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ EVALUATE AND SAVE STATS OUTPUTS @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ #\n",
    "df_mean_combined_hand=pd.concat(df_mean_all_hand) \n",
    "df_peak_combined_hand=pd.concat(df_peak_all_hand)\n",
    "\n",
    "df_mean_combined_back=pd.concat(df_mean_all_back) \n",
    "df_peak_combined_back=pd.concat(df_peak_all_back)\n",
    "\n",
    "hand_save_path = f\"../../../../George Kenefati/EEG/Data/STC ERDS Results/{group}/Combined Stimbased Hand Set {subject_set}/\"\n",
    "if not os.path.exists(hand_save_path):\n",
    "    os.makedirs(hand_save_path)\n",
    "conditions=['Hand HS','Hand LS']\n",
    "stats_plot(df_mean_combined_hand, hand_save_path, 'hand', 'mean')\n",
    "stats_plot(df_peak_combined_hand, hand_save_path, 'hand', 'peak')\n",
    "\n",
    "# change save_path\n",
    "back_save_path = f\"../../../../George Kenefati/EEG/Data/STC ERDS Results/{group}/Combined Stimbased Back Set {subject_set}/\"\n",
    "if not os.path.exists(back_save_path):\n",
    "    os.makedirs(back_save_path)\n",
    "\n",
    "conditions=['Back HS','Back LS']\n",
    "stats_plot(df_mean_combined_back, back_save_path, 'back', 'mean')\n",
    "stats_plot(df_peak_combined_back, back_save_path, 'back', 'peak')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267f956-4f93-4fbe-bb74-949cd733ca2f",
   "metadata": {},
   "source": [
    "#### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042e1b5-cdaa-4533-a1ec-c81d64e97b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file ../../../../George Kenefati/EEG/Data/Processed Data/037_preprocessed-raw.fif...\n",
      "    Range : 0 ... 771039 =      0.000 ...  1927.598 secs\n",
      "Ready.\n",
      "Reading /home/wanglab/Documents/George Kenefati/EEG/eeg-erds-stats/cross subject/../../../../George Kenefati/EEG/Data/Processed Data/037_preprocessed-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     800.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "43 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "<Raw | 037_preprocessed-raw.fif, 64 x 771040 (1927.6 s), ~92 kB, data not loaded>\n",
      "<EpochsFIF |  43 events (all good), -0.2 - 0.8 sec, baseline -0.2 â€“ 0 sec, ~8.5 MB, data loaded,\n",
      " '1000001': 20\n",
      " '1100001': 23\n",
      " 'Yes Pain Back': 0>\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw(os.path.join(processed_info_path,sub_num+'_preprocessed-raw.fif'))\n",
    "epochs = mne.read_epochs(os.path.join(processed_info_path,sub_num+'_preprocessed-epo.fif'))\n",
    "print(raw)\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1470c44-05be-4742-83b7-f495fd391cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<SourceEstimate | 83 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (83, 771040), ~244.1 MB>, <SourceEstimate | 90 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (90, 771040), ~264.7 MB>, <SourceEstimate | 763 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (763, 771040), ~2.19 GB>, <SourceEstimate | 165 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (165, 771040), ~485.3 MB>, <SourceEstimate | 593 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (593, 771040), ~1.70 GB>, <SourceEstimate | 327 vertices, tmin : 0.0 (ms), tmax : 1927597.5 (ms), tstep : 2.5 (ms), data shape : (327, 771040), ~961.8 MB>]\n",
      "(327, 771040)\n",
      "51.40266666666666\n",
      "754716\n",
      "[[-0.5870243  -0.21637547 -0.24306943 ...  0.5622086   0.07323444\n",
      "  -0.1698523 ]\n",
      " [ 0.524224    0.5123593   0.02569015 ...  0.44815588 -0.13421245\n",
      "  -0.46104357]\n",
      " [-0.1819572  -0.31479806 -0.5482398  ...  1.1200479   0.24182144\n",
      "  -0.28045407]\n",
      " ...\n",
      " [ 0.36709595 -0.09876038 -0.09034174 ... -1.0206257  -0.15124688\n",
      "   0.39364612]\n",
      " [ 0.35569298  0.10797694  0.19145185 ... -1.1213778  -0.25332853\n",
      "   0.365903  ]\n",
      " [ 0.42960906 -0.7531699  -1.0261315  ... -0.32299015  0.13062854\n",
      "   0.34265152]]\n"
     ]
    }
   ],
   "source": [
    "print(stc_objects_lst)\n",
    "print(extracted_data_tmp.shape)\n",
    "print(extracted_data_tmp.shape[1] / Fs / 60)\n",
    "print(epo_times[i])\n",
    "print(extracted_data_tmp[:,int(epo_times[i]+tmin*Fs):int(epo_times[i]+tmax*Fs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b7674-d4bc-4dba-8bb8-134ecc02b450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
