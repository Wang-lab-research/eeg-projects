{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5c831f-978e-40da-92ea-40f777c23a1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert Aaron's txt timestamps to .mat files and create Epochs object\n",
    "### Input: Labeled timestamps in .txt files\n",
    "###  Output: *-epo.fif, *-epo_times.mat, and *-stim_labels.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4a5d9a-25ca-40e6-ab1d-4caa1b6e4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_num = \"040\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6312ac7a-2f38-4741-9786-134d83fcd36b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d4a5b-8dfa-4c79-b811-39b8b161a5fe",
   "metadata": {},
   "source": [
    "Define some functions for finding relevant events + event name dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c246eb5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mne.preprocessing import ICA\n",
    "from pyprep.find_noisy_channels import NoisyChannels\n",
    "\n",
    "from autoreject import AutoReject\n",
    "from autoreject import get_rejection_threshold\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "## define label dictionary for epoch annotations\n",
    "## different keys account for different naming conventions\n",
    "## NOTE: the Trigger#X naming convention does not specify between hand and back stimulus\n",
    "custom_mapping = {'eyes closed': 1, 'Trigger#1': 1, 'EYES CLOSED': 1, # eyes closed\n",
    "                  'eyes open': 2, 'eyes opened': 2, 'Trigger#2': 2, 'EYES OPEN': 2, 'eyes openned':2, # eyes open\n",
    "                  'pinprick hand': 3, 'hand pinprick':3, 'Yes Pain Hand': 3, 'Trigger#3': 3, 'HAND PINPRICK': 3, 'hand 32 gauge pinprick': 3, 'Yes Hand Pain': 3,\n",
    "                  # highest intensity pain stimulus (first two HAND)\n",
    "                  'Med Pain Hand': 4 , 'Med Hand Pain': 4 , # intermediate intensity pain stimulus (HAND)\n",
    "                  'No Pain Hand': 5, 'hand plastic':5, 'plastic hand': 5, 'Trigger#4': 5,  'HAND PLASTIC': 5, 'hand plastic filament':5, 'No Hand Pain': 5, \n",
    "                  # sensory stimulus, no pain (first two HAND)\n",
    "                  'pinprick back': 6, 'back pinprick':6, 'Yes Pain Back': 6, 'BACK  PINPRICK': 6, 'Trigger#5': 6, 'back 32 gauge pinprick':6, 'Yes Back Pain': 6,\n",
    "                  # highest intensity pain stimulus (BACK)\n",
    "                  'Med Pain Back': 7, 'Med Back Pain': 7, # intermediate intensity pain stimulus (BACK)\n",
    "                  'plastic back': 8, 'back plastic':8, 'No Pain Back': 8, 'BACK PLASTIC': 8, 'Trigger#6': 8, 'back plastic filament': 8 , 'No Back Pain': 8,\n",
    "                  # sensory stimulus, no pain (BACK)\n",
    "                  'stop': 9, 'Stop': 9, 'STOP': 9, # stop\n",
    "                  '1000001': 10,  '100160': 10, '100480': 10, # lesser weight pen tip down\n",
    "                  '1000010': 11, # lesser weight pen tip up\n",
    "                  '1100001': 12, '100320': 12, '100480': 12, # greater weight pen tip down\n",
    "                  '1100010': 13, # greater weight pen tip up\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af57fe-08f4-4292-a046-65234e1b055f",
   "metadata": {},
   "source": [
    "Import continuous FIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0403a812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "040_preprocessed_avg-raw.fif\n",
      "reading preprocessed-raw file...\n",
      "Opening raw data file ../../../Matlab Code/Processed Data/040_preprocessed_avg-raw.fif...\n",
      "    Range : 0 ... 535839 =      0.000 ...  1339.598 secs\n",
      "Ready.\n",
      "Reading 0 ... 535839  =      0.000 ...  1339.598 secs...\n",
      "Used Annotations descriptions: ['1000001', '1000010', '1100001', '1100010', 'Med Pain Back', 'Med Pain Hand', 'No Pain Back', 'No Pain Hand', 'Stop', 'Yes Pain Back', 'Yes Pain Hand', 'eyes closed', 'eyes opened']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>January 19, 2022  09:58:56 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>64 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>400.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>1.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>040_preprocessed_avg-raw.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:22:19 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | 040_preprocessed_avg-raw.fif, 64 x 535840 (1339.6 s), ~261.7 MB, data loaded>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subject ID\n",
    "data_dir = \"../../../Matlab Code/Processed Data/\"\n",
    "# data_dir = \"../../../Matlab Code/Processed Data - Needing Marker Repair/\"\n",
    "\n",
    "# sub_num = sys.argv[1]\n",
    "\n",
    "sub_id=''\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.startswith(sub_num) and file.endswith('raw.fif'):\n",
    "        sub_id = file\n",
    "\n",
    "print(f\"{sub_id}\\nreading preprocessed-raw file...\")\n",
    "raw = mne.io.read_raw_fif(data_dir+sub_id, preload=True)\n",
    "\n",
    "res_freq = raw.info['sfreq'] # save resampled sampling frequency\n",
    "\n",
    "(events_from_annot, event_dict) = mne.events_from_annotations(raw, event_id=custom_mapping)\n",
    "\n",
    "# get key and val lists from event_dict\n",
    "key_list = list(event_dict.keys())\n",
    "val_list = list(event_dict.values())\n",
    "\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71598e-7a29-4ae6-870e-88a98922a77d",
   "metadata": {},
   "source": [
    "Get original sampling frequency (orig_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c499ef6-c6ff-467e-8879-2f34170d1ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_freq:  1000.0\n"
     ]
    }
   ],
   "source": [
    "orig_data_dir = \"../../../EEG DATA/\"\n",
    "sub_id=''; acq_id=''\n",
    "for folder in os.listdir(orig_data_dir):\n",
    "    if folder.startswith(sub_num):\n",
    "        sub_id = folder;\n",
    "for subfile in os.listdir(os.path.join(orig_data_dir,sub_id)):\n",
    "    if subfile.endswith(\".edf\"):\n",
    "        acq_id = subfile\n",
    "eeg_data_raw_file = os.path.join(orig_data_dir,sub_id,acq_id)\n",
    "orig_raw = mne.io.read_raw_edf(eeg_data_raw_file, preload=False)\n",
    "display.clear_output(wait=True)\n",
    "\n",
    "orig_freq = orig_raw.info['sfreq']\n",
    "print('orig_freq: ', orig_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d8f36-bff8-4e4b-8654-5e2d97764fb3",
   "metadata": {},
   "source": [
    "Validate channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616a667f-cb6d-4e78-8c20-caa9a34f8484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1', 'Fpz', 'Fp2', 'AF3', 'AF4', 'F11', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'F12', 'FT11', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT12', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'M1', 'M2', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Cb1', 'Cb2']\n"
     ]
    }
   ],
   "source": [
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a85340-781e-4083-98a4-721f3adf900e",
   "metadata": {},
   "source": [
    "Check event labels and see whether either key presses or pinprick markers are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59a848b-a2bf-45c7-88a0-8f623fb24794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n",
      "['No Pain Hand' '1100001' '1100010' '1100001' '1100010' '1100001'\n",
      " '1100010' '1100001' '1100010' '1100001' '1100010' '1100001' '1100010'\n",
      " 'No Pain Hand' '1100001' '1100010' '1100001' '1100010' 'Yes Pain Hand'\n",
      " '1000001' '1000010' '1000001' '1000010' 'No Pain Hand' '1100001'\n",
      " '1100010' '1100001' '1100010' 'Yes Pain Hand' '1000001' '1000010'\n",
      " '1000001' '1000010' '1000001' '1000010' 'Yes Pain Hand' '1000001'\n",
      " '1000010' 'Yes Pain Back' '1000001' '1000010' '1000001' '1000010'\n",
      " '1000001' '1000010' '1000001' '1000010' 'Yes Pain Back' '1000001'\n",
      " '1000010']\n"
     ]
    }
   ],
   "source": [
    "desc_full = raw.annotations.description\n",
    "desc_full = desc_full.tolist()\n",
    "print(len(desc_full))\n",
    "print(raw.annotations.description[200:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ef60ac-5732-4922-8f9a-79e057d71f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create events to epochize data\n",
    "# print(f\"{sub_id}\\ncreating events and epochizing data...\")\n",
    "# (events_from_annot, event_dict) = mne.events_from_annotations(raw, event_id=custom_mapping)\n",
    "\n",
    "# # get key and val lists from event_dict\n",
    "# key_list = list(event_dict.keys())\n",
    "# val_list = list(event_dict.values())\n",
    "\n",
    "# epochs = mne.Epochs(raw, events_from_annot, event_dict, tmin=-0.2, tmax=0.8, proj=True, preload=True,\n",
    "#                     event_repeated='drop')#, baseline=(None,0))\n",
    "# display.clear_output(wait=True)\n",
    "\n",
    "# epochs\n",
    "\n",
    "# # del raw # clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457284e0-a186-48c5-a2bd-906e031c3681",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load in .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac2813b-8184-4dff-9650-652a36b3acc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type before reconstruction :  <class 'str'>\n",
      "Data type after reconstruction :  <class 'dict'>\n",
      "{'No Pain Hand': [793514, 810065, 815845, 836574, 842263, 970714, 988803, 1006030, 1010686, 1025950], 'Med Pain Hand': [782882, 800810, 822903, 849715, 855031, 1172939, 1189615, 1207044, 1211915, 1227031], 'Yes Pain Hand': [980273, 996952, 1020144, 1034250, 1038958, 1157433, 1163225, 1194935, 1221280, 1234585], 'No Pain Back': [869068, 877200, 903315, 928169, 946597, 1066960, 1075737, 1093066, 1111296, 1128097], 'Med Pain Back': [885202, 894064, 911719, 917917, 935719, 1252519, 1277194, 1306179, 1320372, 1329104], 'Yes Pain Back': [1050112, 1058443, 1085396, 1104517, 1120961, 1259576, 1266695, 1283634, 1290374, 1313201]}\n"
     ]
    }
   ],
   "source": [
    "# IMPORT DICT WITH EVENT TIMES CREATED BY AARON\n",
    "\n",
    "import json\n",
    "  \n",
    "txt_dir = \"../../Re__EEG_BCI_Project/\"\n",
    "\n",
    "# reading the data from the file\n",
    "with open(txt_dir+sub_num[:3]+\".txt\") as f:\n",
    "    data = f.read()\n",
    "    data = data.replace(\"'\", '\"')\n",
    "\n",
    "print(\"Data type before reconstruction : \", type(data))\n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "js = json.loads(data)\n",
    "  \n",
    "print(\"Data type after reconstruction : \", type(js))\n",
    "print(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bddefd-4f83-45d7-971e-dc6174aeafcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[793514, 810065, 815845, 836574, 842263, 970714, 988803, 1006030, 1010686, 1025950, 782882, 800810, 822903, 849715, 855031, 1172939, 1189615, 1207044, 1211915, 1227031, 980273, 996952, 1020144, 1034250, 1038958, 1157433, 1163225, 1194935, 1221280, 1234585, 869068, 877200, 903315, 928169, 946597, 1066960, 1075737, 1093066, 1111296, 1128097, 885202, 894064, 911719, 917917, 935719, 1252519, 1277194, 1306179, 1320372, 1329104, 1050112, 1058443, 1085396, 1104517, 1120961, 1259576, 1266695, 1283634, 1290374, 1313201]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# Create lists for events and labels from Aaron's txt file\n",
    "txt_samps_list = [item for sublist in list(js.values()) for item in sublist]\n",
    "print(txt_samps_list)\n",
    "print(len(txt_samps_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3455c135-5bfa-4d9a-8196-118dc9c820f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'No Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Med Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'Yes Pain Hand', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'No Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Med Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back', 'Yes Pain Back']\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# Create corresponding list of labels\n",
    "txt_labels_list = []\n",
    "for key in js:\n",
    "    txt_labels_list.append([key]*(len(js[key])))\n",
    "    \n",
    "txt_labels_list = [item for sublist in txt_labels_list for item in sublist]\n",
    "\n",
    "print(txt_labels_list)\n",
    "print(len(txt_labels_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d0e9cb-d281-4e9e-a3ee-44f676ab14f4",
   "metadata": {},
   "source": [
    "## Convert txt_times_list and txt_labels_list to appropriate format for Epochs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf70433d-989f-4e0c-b3d9-3cbdf27fa785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  0 11  1  2 12  3  4 13 14 30 31 40 41 32 42 43 33 44 34  5 20  6 21\n",
      "  7  8 22  9 23 24 50 51 35 36 52 37 53 38 54 39 25 26 15 16 27 17 18 28\n",
      " 19 29 45 55 56 46 57 58 47 59 48 49]\n",
      "[782882, 793514, 800810, 810065, 815845]\n",
      "['Med Pain Hand', 'No Pain Hand', 'Med Pain Hand', 'No Pain Hand', 'No Pain Hand']\n"
     ]
    }
   ],
   "source": [
    "# Sort lists in chronological order and permute event and label lists accordingly\n",
    "\n",
    "txt_times_arr = np.array(txt_samps_list)\n",
    "sort_index = np.argsort(txt_samps_list)\n",
    "print(sort_index)\n",
    "\n",
    "# Permute times and labels lists:\n",
    "txt_samps_list = [txt_samps_list[i] for i in sort_index]\n",
    "txt_labels_list = [txt_labels_list[i] for i in sort_index]\n",
    "\n",
    "print(txt_samps_list[:5])\n",
    "print(txt_labels_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430b97d5-618f-4143-90fa-f5dda83ca44b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pinprick hand', 'hand pinprick', 'Yes Pain Hand', 'Trigger#3', 'HAND PINPRICK', 'hand 32 gauge pinprick', 'Yes Hand Pain']\n",
      "['Med Pain Hand', 'Med Hand Pain']\n",
      "['No Pain Hand', 'hand plastic', 'plastic hand', 'Trigger#4', 'HAND PLASTIC', 'hand plastic filament', 'No Hand Pain']\n",
      "['pinprick back', 'back pinprick', 'Yes Pain Back', 'BACK  PINPRICK', 'Trigger#5', 'back 32 gauge pinprick', 'Yes Back Pain']\n",
      "['Med Pain Back', 'Med Back Pain']\n",
      "['plastic back', 'back plastic', 'No Pain Back', 'BACK PLASTIC', 'Trigger#6', 'back plastic filament', 'No Back Pain']\n"
     ]
    }
   ],
   "source": [
    "# define labels in separate lists\n",
    "custom_mapping.keys()\n",
    "# hand\n",
    "yes_hand_pain_list = list(custom_mapping.keys())[8:15]\n",
    "print(yes_hand_pain_list)\n",
    "\n",
    "med_hand_pain_list = list(custom_mapping.keys())[15:17]\n",
    "print(med_hand_pain_list)\n",
    "\n",
    "no_hand_pain_list = list(custom_mapping.keys())[17:24]\n",
    "print(no_hand_pain_list)\n",
    "\n",
    "# back\n",
    "yes_back_pain_list = list(custom_mapping.keys())[24:31]\n",
    "print(yes_back_pain_list)\n",
    "\n",
    "med_back_pain_list = list(custom_mapping.keys())[31:33]\n",
    "print(med_back_pain_list)\n",
    "\n",
    "no_back_pain_list = list(custom_mapping.keys())[33:40]\n",
    "print(no_back_pain_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b8b81-d1e9-4758-b223-d9348c091c8c",
   "metadata": {},
   "source": [
    "Change string labels to keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d3e82-c68f-40fa-9fd6-dde098c271dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change labels to keys\n",
    "def labels_to_keys(txt_labels_list, val_list):\n",
    "    stim_labels = [0]*len(txt_labels_list)\n",
    "    if 10 in val_list or 11 in val_list or 12 in val_list or 13 in val_list:\n",
    "        for i in range(0,len(stim_labels)):\n",
    "            if txt_labels_list[i] in yes_hand_pain_list:\n",
    "                    stim_labels[i] = 3\n",
    "            elif txt_labels_list[i] in med_hand_pain_list:\n",
    "                    stim_labels[i] = 4\n",
    "            elif txt_labels_list[i] in no_hand_pain_list:\n",
    "                    stim_labels[i] = 5\n",
    "            elif txt_labels_list[i] in yes_back_pain_list:\n",
    "                    stim_labels[i] = 6\n",
    "            elif txt_labels_list[i] in med_back_pain_list:\n",
    "                    stim_labels[i] = 7\n",
    "            elif txt_labels_list[i] in no_back_pain_list:\n",
    "                    stim_labels[i] = 8\n",
    "                \n",
    "    if 10 not in val_list or 11 not in val_list or 12 not in val_list or 13 not in val_list:\n",
    "        for i in range(0,len(stim_labels)):\n",
    "            if txt_labels_list[i] in yes_hand_pain_list:\n",
    "                stim_labels[i] = 3\n",
    "            elif txt_labels_list[i] in no_hand_pain_list:\n",
    "                stim_labels[i] = 4\n",
    "            elif txt_labels_list[i] in yes_back_pain_list:\n",
    "                stim_labels[i] = 5\n",
    "            elif txt_labels_list[i] in no_back_pain_list:\n",
    "                stim_labels[i] = 6\n",
    "\n",
    "    # extract only integer keys\n",
    "    key_els = [num for num in stim_labels if isinstance(num, (int))]        \n",
    "    \n",
    "    return key_els\n",
    "\n",
    "keys_frm_txt = labels_to_keys(txt_labels_list, val_list)\n",
    "\n",
    "# print key list\n",
    "print(keys_frm_txt)\n",
    "len(keys_frm_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeda501-524e-4524-bb66-0156fd16f729",
   "metadata": {},
   "source": [
    "## Compare txt labels to ground truth (excel file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf175e-d7cc-4a1c-913f-15143d4a4fe6",
   "metadata": {},
   "source": [
    "Import excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7740c54-15e6-43a3-9efc-440976f11178",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT 40 Pinprick.xlsx\n"
     ]
    }
   ],
   "source": [
    "# import pain ratings to compare to annotations\n",
    "import pandas as pd\n",
    "eeg_dir = \"../../../EEG DATA/\"\n",
    "# edf_dir = (sub_num+\"EEGDATA/\")\n",
    "\n",
    "for file in os.listdir(eeg_dir):\n",
    "    # print(file)\n",
    "    if file.startswith(sub_num): # and os.path.isdir(file)):\n",
    "        edf_dir = file\n",
    "        \n",
    "for file in os.listdir(eeg_dir+edf_dir):\n",
    "    if file.endswith(\".xlsx\"):\n",
    "        xfname = file\n",
    "\n",
    "df = pd.read_excel((eeg_dir+edf_dir+'/'+xfname), sheet_name=0) # can also index sheet by name or fetch all sheets\n",
    "\n",
    "# hand rows\n",
    "# row_start_hand = 14\n",
    "excel_list_hand = df['PIN PRICK PAIN SCALE '][3:].tolist() #[row_start_hand:54]\n",
    "\n",
    "# # back rows\n",
    "# row_start_back = 57\n",
    "# excel_list_back = df['PIN PRICK PAIN SCALE '][row_start_back:].tolist()\n",
    "\n",
    "# concatenate lists\n",
    "excel_list = excel_list_hand# + excel_list_back\n",
    "\n",
    "print(xfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b583e-d1c8-44ad-b788-0eb331b2a94d",
   "metadata": {},
   "source": [
    "#### Look for mismatch between stimulus types from excel sheet to those of the .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c442d3-7291-47f6-b225-8959e47a8fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From txt file:\n",
      "[4, 5, 4, 5, 5, 4, 5, 5, 4, 4, 8, 8, 7, 7, 8, 7, 7, 8, 7, 8, 5, 3, 5, 3, 5, 5, 3, 5, 3, 3, 6, 6, 8, 8, 6, 8, 6, 8, 6, 8, 3, 3, 4, 4, 3, 4, 4, 3, 4, 3, 7, 6, 6, 7, 6, 6, 7, 6, 7, 7]\n",
      "60\n",
      "GROUND TRUTH: \n",
      "[4, 5, 4, 5, 5, 4, 5, 5, 4, 4, 8, 8, 7, 7, 8, 7, 7, 8, 7, 8, 5, 3, 5, 3, 5, 5, 3, 5, 3, 3, 6, 6, 8, 8, 6, 8, 6, 8, 6, 8, 3, 3, 4, 4, 3, 4, 4, 3, 4, 3, 7, 6, 6, 7, 6, 6, 7, 6, 7, 7]\n",
      "60\n",
      "\n",
      "Do the lists match?\n",
      "Yes.\n"
     ]
    }
   ],
   "source": [
    "ground_truth = excel_list\n",
    "markers = keys_frm_txt\n",
    "\n",
    "print('From txt file:')\n",
    "print(markers)\n",
    "print(len(markers))\n",
    "\n",
    "print('GROUND TRUTH: ')\n",
    "print(excel_list)\n",
    "print(len(excel_list))\n",
    "\n",
    "print('\\nDo the lists match?')\n",
    "mtch_ans = 'Yes.' if excel_list == markers else 'No!'\n",
    "print(mtch_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ba0f05-f0d8-467f-a54f-928e331bc87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No (more) mismatches found. Exiting loop.\n"
     ]
    }
   ],
   "source": [
    "mismatch_list = []\n",
    "for i, el in enumerate(markers):\n",
    "    # find mismatch\n",
    "    try:\n",
    "        mismatch = next( (idx, x, y) for idx, (x, y) in enumerate(zip(markers, ground_truth)) if x!=y )\n",
    "    except: \n",
    "        print('No (more) mismatches found. Exiting loop.')\n",
    "        break\n",
    "    else:\n",
    "        iss_i = mismatch[0]; print(iss_i)\n",
    "        # point mismatch, extra label, or missing?\n",
    "        if markers[iss_i+1:iss_i+1+3] == ground_truth[iss_i+1:iss_i+1+3]:\n",
    "            markers[iss_i] = mismatch[2]\n",
    "            print(f'Point error mismatch: changed label {mismatch[1]} to {mismatch[2]} in [keys_frm_txt]\\n')\n",
    "            \n",
    "        elif markers[iss_i+1:iss_i+1+3] == ground_truth[iss_i:iss_i+3]:\n",
    "            del markers[iss_i]; del txt_samps_list[iss_i]\n",
    "            print(f'Extra label mismatch: expected {mismatch[2]}, deleted label {mismatch[1]} from [keys_frm_txt].\\n')\n",
    "            \n",
    "        elif markers[iss_i+1:iss_i+1+3] == ground_truth[iss_i+1+1:iss_i+1+1+3]:\n",
    "            del ground_truth[iss_i]; del txt_samps_list[iss_i]\n",
    "            print(f'Missing label mismatch: expected {mismatch[2]}, deleted label {mismatch[2]} from [ground_truth] and from [txt_samps_list].\\n')\n",
    "            \n",
    "keys_frm_txt = markers\n",
    "excel_list = ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e721cdc-5c9e-4425-952e-2c2f38424a4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Check resulting labels list and ground_truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50b71bff-d7bc-4979-9aae-ab02c15eaa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels already match.\n"
     ]
    }
   ],
   "source": [
    "if mtch_ans == 'No!':\n",
    "    print('AFTER CORRECTION:\\n')\n",
    "\n",
    "    print('From txt file:')\n",
    "    print(keys_frm_txt)\n",
    "    print(len(keys_frm_txt))\n",
    "\n",
    "    print('GROUND TRUTH: ')\n",
    "    print(excel_list)\n",
    "    print(len(excel_list))\n",
    "\n",
    "    print('\\nDo the lists match now?')\n",
    "    mtch_ans = 'Yes.' if excel_list == keys_frm_txt else 'No!'\n",
    "    print(mtch_ans)\n",
    "else: \n",
    "    print('Labels already match.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe28daf-a2ad-4f3c-82e9-3c741d7b7896",
   "metadata": {},
   "source": [
    "## Create Epochs object and complete preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982cfb05-5a03-446a-81b6-c8df59b8f417",
   "metadata": {},
   "source": [
    "#### Ensure samples are in correct sampling frequency, do this in below loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "503c26d4-cb42-45fd-ace5-b46aeb613796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[313152      0      4]\n",
      " [317405      0      5]\n",
      " [320324      0      4]\n",
      " [324026      0      5]\n",
      " [326338      0      5]]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# create events array for input to Epochs\n",
    "events_from_txt_tmp = [] # first as list \n",
    "txt_samps_list_res = txt_samps_list\n",
    "\n",
    "for i in range(0, len(txt_samps_list)):\n",
    "    txt_samps_list_res[i] = int( np.floor(txt_samps_list[i]*(res_freq/orig_freq) ) )\n",
    "    events_from_txt_tmp.append([txt_samps_list_res[i], 0, keys_frm_txt[i]])\n",
    "\n",
    "events_from_txt_arr = np.array(events_from_txt_tmp)\n",
    "print(events_from_txt_arr[:5])\n",
    "print(len(events_from_txt_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "593391a4-5e75-4f8f-b00c-ac1055bb2148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>3: 10<br/>4: 10<br/>5: 10<br/>6: 10<br/>7: 10<br/>8: 10</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 0.800 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  60 events (all good), -0.2 - 0.8 sec, baseline -0.2 – 0 sec, ~11.8 MB, data loaded,\n",
       " '3': 10\n",
       " '4': 10\n",
       " '5': 10\n",
       " '6': 10\n",
       " '7': 10\n",
       " '8': 10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create events to epochize data\n",
    "print(f\"{sub_id}\\ncreating events and epochizing data...\")\n",
    "\n",
    "epochs = mne.Epochs(raw, events_from_txt_arr, tmin=-0.2, tmax=0.8, proj=True, preload=True,\n",
    "                    event_repeated='drop')#, baseline=(None,0))\n",
    "display.clear_output(wait=True)\n",
    "\n",
    "epochs\n",
    "\n",
    "# del raw # clear memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd671c22-fa38-4d4a-a0e9-46ba7c4c3360",
   "metadata": {},
   "source": [
    "## Perform AutoReject and Save .mat Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d615fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "040.EEGDATA.1.19.2022\n",
      "finding epochs to clean...\n",
      "Running autoreject on ch_type=eeg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801b70ce89d44a36912c5de653a6b5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Creating augmented epochs : 0/64 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7901bd4f15c348d09ef9d19377bd190e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Computing thresholds ... : 0/64 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932557196ed74f5b8fd15a0bb03302d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/60 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72e503abcff41a58c499660c72b640a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | n_interp : 0/3 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935db2e87de04f2883bb9050637d5da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/60 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cceebff7b44c2a88bff926e71b33f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803de826aedb478fad7d810d80a6f71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/60 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e0104d103a4166aa87b9be6497a6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45bbaa94a864e5abe5dc6e204043fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/60 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2a33c112204ace948306b033df5724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Fold : 0/10 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimated consensus=0.30 and n_interpolate=4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989bd1248d8d469da4998e91e6eb9b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Repairing epochs : 0/60 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 8 epochs: 0, 15, 17, 24, 31, 42, 56, 58\n",
      "<autoreject.autoreject.RejectLog object at 0x7f362a6f50d0>\n"
     ]
    }
   ],
   "source": [
    "# use autoreject package to automatically clean epochs \n",
    "print(f\"{sub_id}\\nfinding epochs to clean...\")\n",
    "stim_epochs = epochs; del epochs\n",
    "ar = AutoReject(random_state=42)\n",
    "_, reject_log = ar.fit_transform(stim_epochs, return_log=True)\n",
    "print(reject_log)\n",
    "# display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e581779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 8 epochs:  [0, 15, 17, 24, 31, 42, 56, 58]\n",
      "\n",
      "Saving processed epochs...\n",
      "Overwriting existing file.\n",
      "\n",
      "Saving drop_log as mat file...\n",
      "\n",
      "Saving epo_times as mat file...\n",
      "\n",
      "Saving stim labels as mat file...\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# drop rejected epochs\n",
    "bad_epochs_bool = reject_log.bad_epochs.tolist()\n",
    "dropped_epochs_list = [i for i, val in enumerate(bad_epochs_bool) if val]\n",
    "print(f'Dropped {len(dropped_epochs_list)} epochs: ', dropped_epochs_list)\n",
    "\n",
    "data_dir = \"../../../Matlab Code/Processed Data/\"\n",
    "\n",
    "# save processed epochs\n",
    "print(\"\\nSaving processed epochs...\")\n",
    "\n",
    "save_fname = sub_id[:3] + '_preprocessed_txt-epo'\n",
    "\n",
    "stim_epochs.save(data_dir + save_fname + '.fif', \n",
    "         verbose=True, overwrite=True)\n",
    "\n",
    "# epo_set_dir = '../../../Matlab Code/SET Data/epo/'\n",
    "# mne.export.export_epochs(epo_set_dir+ save_fname + '.set', \n",
    "#                          stim_epochs, overwrite=True, verbose=True)\n",
    "\n",
    "# save drop log\n",
    "print(\"\\nSaving drop_log as mat file...\")\n",
    "mdic = {\"drop_log\": dropped_epochs_list}\n",
    "savemat(data_dir+sub_id[:3]+'_txt_drop_log.mat', mdic)\n",
    "\n",
    "# save epo_times\n",
    "print(\"\\nSaving epo_times as mat file...\")\n",
    "stim_events = txt_samps_list_res\n",
    "mdic = {\"epo_times\": stim_events}\n",
    "savemat(data_dir+sub_id[:3]+'_txt_epo_times.mat', mdic)\n",
    "\n",
    "# save stim labels\n",
    "print(\"\\nSaving stim labels as mat file...\")\n",
    "mdic = {\"epo_times\": excel_list}\n",
    "savemat(data_dir+sub_id[:3]+'_txt_stim_labels.mat', mdic)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "# display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4382095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjust events_from_annot for repeated events that are dropped by MNE\n",
    "# print(f\"{sub_id}\\nRemoving repeated epochs from annotations...\")\n",
    "# epochs_drop_log = list(epochs.drop_log)\n",
    "# epochs_drop_ids = [idx for idx, tup in enumerate(epochs_drop_log) if epochs_drop_log[idx]]\n",
    "# events_from_annot_list = events_from_annot.tolist()\n",
    "# delete_multiple_elements(events_from_annot_list, epochs_drop_ids)\n",
    "# events_from_annot_new = np.array(events_from_annot_list)\n",
    "# print(f\"\\nDropped {len(raw.annotations) - len(events_from_annot_new)} repeated epochs\")\n",
    "# # display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda5f3a2-a0c5-4f14-880e-de6f1362f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find epochs only from stim events\n",
    "# print(f\"{sub_id}\\nfinding the 60 pin-prick epochs...\")\n",
    "# [stim_labels, StimOn_ids] = get_stim_epochs(epochs,events_from_annot_new,event_dict)\n",
    "\n",
    "# stim_epochs = epochs[StimOn_ids]\n",
    "# # display.clear_output(wait=True)\n",
    "\n",
    "# print(stim_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1889ba51-00a6-428a-b2ca-bab0f4551eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatch_list = []\n",
    "# for i, k in enumerate(excel_list):\n",
    "#     # find mismatch\n",
    "#     try:\n",
    "#         mismatch = next( (idx, x, y) for idx, (x, y) in enumerate(zip(txt_labels_list, excel_list)) if x!=y )\n",
    "#     except:\n",
    "#         print(\"No more mismatches found\")\n",
    "#         break\n",
    "#     print(\"index, incorrect value, correct value:\", mismatch)\n",
    "#     # delete mismatch\n",
    "#     del key_els[mismatch[0]]\n",
    "#     # save mismatch index\n",
    "#     mismatch_list.append(mismatch[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0630521a-11e5-407e-8481-27c33f12a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mismatch_list)\n",
    "\n",
    "# mismatch_id=[]\n",
    "# # convert mismatch to indices\n",
    "# for i, m in enumerate(mismatch_list):\n",
    "#     mismatch_id.append( mismatch_list[i] + i )\n",
    "    \n",
    "# print(mismatch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7abbcd3d-2234-465a-9fad-1f5ef2e40323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop certain stim event\n",
    "\n",
    "# drop_list = []\n",
    "# # drop_list=[12,] # C17\n",
    "# # drop_list = [0,15] # PT C5\n",
    "# # drop_list = mismatch_id # PT C3\n",
    "# # drop_list = [6,11] # PT C2\n",
    "# # drop_list = [14, 15, 16] # PT 050\n",
    "# # drop_list = [40,41,66] # PT 009\n",
    "\n",
    "# # delete from StimOn\n",
    "# delete_multiple_elements(StimOn_ids, drop_list)\n",
    "                         \n",
    "# # delete from epochs object\n",
    "# stim_epochs.drop(drop_list)\n",
    "\n",
    "# # verify deletion\n",
    "# print(len(StimOn_ids))\n",
    "# stim_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "062edee9-5fe4-480d-8d37-b2b2be33f599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'txt_samps_list_resamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# find intersect \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(events_samps)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m event_times_intersect \u001b[38;5;241m=\u001b[39m [value \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtxt_samps_list_resamp\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m events_samps]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(event_times_intersect)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(event_times_intersect))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'txt_samps_list_resamp' is not defined"
     ]
    }
   ],
   "source": [
    "# find intersect \n",
    "# print(events_samps)\n",
    "\n",
    "event_times_intersect = [value for value in txt_samps_list_resamp if value in events_samps]\n",
    "print(event_times_intersect)\n",
    "print(len(event_times_intersect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685eb2e2-04d3-42f0-82eb-f5ca2d64be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract indices of all events where intersection occurs to print epochs object\n",
    "ab, a_ind, b_ind = np.intersect1d(events_samps,event_times_intersect, return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4207c31-b5d8-4418-9e51-fec2995547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb73f1c-42ec-4ff9-b067-aae66a14804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_intersect = epochs[a_ind]\n",
    "\n",
    "epochs_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a44076-830a-4681-acee-14e97ee0af5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_env",
   "language": "python",
   "name": "eeg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
